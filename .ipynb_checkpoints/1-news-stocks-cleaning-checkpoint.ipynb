{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "pd.options.display.max_rows = 6000\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models, matutils\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "\n",
       "                                          Top2  \\\n",
       "0      b'BREAKING: Musharraf to be impeached.'   \n",
       "1  b'Bush puts foot down on Georgian conflict'   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...  ...   \n",
       "1  b'An American citizen living in S.Ossetia blam...  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia ge...   \n",
       "1  b'Israel and the US behind the Georgian aggres...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "\n",
       "                                               Top25  \n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex fo...  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Combined_News_DJIA.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Georgia \\'downs two Russian warplanes\\' as countries move to brink of war\"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1989, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1989 entries, 0 to 1988\n",
      "Data columns (total 27 columns):\n",
      "Date     1989 non-null object\n",
      "Label    1989 non-null int64\n",
      "Top1     1989 non-null object\n",
      "Top2     1989 non-null object\n",
      "Top3     1989 non-null object\n",
      "Top4     1989 non-null object\n",
      "Top5     1989 non-null object\n",
      "Top6     1989 non-null object\n",
      "Top7     1989 non-null object\n",
      "Top8     1989 non-null object\n",
      "Top9     1989 non-null object\n",
      "Top10    1989 non-null object\n",
      "Top11    1989 non-null object\n",
      "Top12    1989 non-null object\n",
      "Top13    1989 non-null object\n",
      "Top14    1989 non-null object\n",
      "Top15    1989 non-null object\n",
      "Top16    1989 non-null object\n",
      "Top17    1989 non-null object\n",
      "Top18    1989 non-null object\n",
      "Top19    1989 non-null object\n",
      "Top20    1989 non-null object\n",
      "Top21    1989 non-null object\n",
      "Top22    1989 non-null object\n",
      "Top23    1988 non-null object\n",
      "Top24    1986 non-null object\n",
      "Top25    1986 non-null object\n",
      "dtypes: int64(1), object(26)\n",
      "memory usage: 419.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# topic 23 has 1 missing value, 24 &25 have 3 missing values\n",
    "# This is not an issue because we are going to combine the news into one document for each day.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1065\n",
       "0     924\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the two classes are balanced\n",
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "-  remove date column, because we are trying to see if the same day headlines can affect the same day stock close value.\n",
    "-  combine each day's 25 news into one document\n",
    "-  write a function to convert one string into a list of words\n",
    "-  convert every document in df.news into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the date column\n",
    "# the stock close trend is directly affected by the news from the same day.\n",
    "df = df.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all 25 news of the same day into a long string for doc2vec and vectorization.\n",
    "combine_news = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    combine_news.append(' '.join(str(x) for x in row[1:]))\n",
    "df['news'] = pd.DataFrame(combine_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Georgia \\'downs two Russian warplanes\\' as countries move to brink of war\" b\\'BREAKING: Musharraf to be impeached.\\' b\\'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)\\' b\\'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire\\' b\"Afghan children raped with \\'impunity,\\' U.N. official says - this is sick, a three year old was raped and they do nothing\" b\\'150 Russian tanks have entered South Ossetia whilst Georgia shoots down two Russian jets.\\' b\"Breaking: Georgia invades South Ossetia, Russia warned it would intervene on SO\\'s side\" b\"The \\'enemy combatent\\' trials are nothing but a sham: Salim Haman has been sentenced to 5 1/2 years, but will be kept longer anyway just because they feel like it.\" b\\'Georgian troops retreat from S. Osettain capital, presumably leaving several hundred people killed. [VIDEO]\\' b\\'Did the U.S. Prep Georgia for War with Russia?\\' b\\'Rice Gives Green Light for Israel to Attack Iran: Says U.S. has no veto over Israeli military ops\\' b\\'Announcing:Class Action Lawsuit on Behalf of American Public Against the FBI\\' b\"So---Russia and Georgia are at war and the NYT\\'s top story is opening ceremonies of the Olympics?  What a fucking disgrace and yet further proof of the decline of journalism.\" b\"China tells Bush to stay out of other countries\\' affairs\" b\\'Did World War III start today?\\' b\\'Georgia Invades South Ossetia - if Russia gets involved, will NATO absorb Georgia and unleash a full scale war?\\' b\\'Al-Qaeda Faces Islamist Backlash\\' b\\'Condoleezza Rice: \"The US would not act to prevent an Israeli strike on Iran.\" Israeli Defense Minister Ehud Barak: \"Israel is prepared for uncompromising victory in the case of military hostilities.\"\\' b\\'This is a busy day:  The European Union has approved new sanctions against Iran in protest at its nuclear programme.\\' b\"Georgia will withdraw 1,000 soldiers from Iraq to help fight off Russian forces in Georgia\\'s breakaway region of South Ossetia\" b\\'Why the Pentagon Thinks Attacking Iran is a Bad Idea - US News &amp; World Report\\' b\\'Caucasus in crisis: Georgia invades South Ossetia\\' b\\'Indian shoe manufactory  - And again in a series of \"you do not like your work?\"\\' b\\'Visitors Suffering from Mental Illnesses Banned from Olympics\\' b\"No Help for Mexico\\'s Kidnapping Surge\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the news headlines for 08/08/2008\n",
    "df.loc[0,'news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' U.N.', ' U.S.', ' U.K.', ' S.A.', ' U.S.C.', ' D.C.', ' N.J.',\n",
       "       ' i.e.', ' P.I.', ' A.N.C.', ' a.m.', ' A.K.A.', ' P.R.', ' R.I.',\n",
       "       'nU.S.', ' E.U.', ' H.I.V.', ' I.H.T.', ' B.C.', ' J.P.', ' N.S.',\n",
       "       'crimese.g.', ' C.I.A.', ' p.m.', 'Ph.D.', ' N.Y.', ' U.A.E.',\n",
       "       'sq.m.', ' I.M.F.', ' y.o.', ' i.a.', ' I.D.', ' M.A.', ' H.W.',\n",
       "       ' O.K.', ' N.K.', ' B.S.', ' A.T.M.', ' W.H.O.', ' N.S.A.',\n",
       "       ' P.M.', ' F.B.I.', ' P.E.I.', ' a.k.a.', ' S.E.', ' A.D.',\n",
       "       ' T.B.', ' J.K.', ' L.G.B.T.'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the 2/3 character abbrevations from the string corpus. Convert them to full form. \n",
    "# Then we can remove the punctuations without worrying losing the meaning of the abbrevation words.\n",
    "\n",
    "# combine all the news into a very long string\n",
    "long_news_str = '   '.join(df.news)\n",
    "\n",
    "# find all the abbrevations of 2 and 3 characters\n",
    "def find_abbr(text):\n",
    "    abbr = []\n",
    "    for i in re.finditer(r\"([A-Za-z]+| )([A-Za-z]\\.){2,}\", text):\n",
    "        abbr.append(i.group())\n",
    "    df_abbr = pd.Series(abbr)\n",
    "    return df_abbr.unique()\n",
    "\n",
    "find_abbr(long_news_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ready stop words for the tokenization function below\n",
    "mywords = ['breaking','whilst', 'say', 'says', 'today','yesterday', 'news', 'tomorrow','iii', 'ii', 'like', 'ha',]\n",
    "final_stop = stopwords.words('english') + mywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text, remove_stop_words=True, lemma_words=True):\n",
    "    \n",
    "    ''' Clean each document into a list of words:\n",
    "    1. convert abbrevations to full words\n",
    "    2. tokenize the text\n",
    "    3. remove non-alphabetic characters and one-letter words, including numbers and punctuations\n",
    "    4. remove stop words\n",
    "    '''\n",
    "    # clean the text, convert only the abbrs that are meaningful\n",
    "    text = re.sub(r\" A.T.M. \", \" Automated Teller Machine \", text)\n",
    "    text = re.sub(r\" C.I.A. \", \" Central Intelligence Agency \", text)\n",
    "    text = re.sub(r\" D.C. \", \" District of columbia \", text)\n",
    "    text = re.sub(r\" E.U. \", \" Europian Union \", text)\n",
    "    text = re.sub(r\" F.B.I. \", \" Federal Bureau of Investigation \", text)\n",
    "    text = re.sub(r\" H.I.V. \", \" Human immunodeficiency virus \", text)\n",
    "    text = re.sub(r\" I.H.T. \", \" inheritance tax \", text)\n",
    "    text = re.sub(r\" I.M.F. \", \" International Monetary Fund \", text)\n",
    "    text = re.sub(r\" I.D. \", \" identification \", text)\n",
    "    text = re.sub(r\" L.G.B.T. \", \" minority \", text)\n",
    "    text = re.sub(r\" M.A. \", \" Massachusetts \", text)\n",
    "    text = re.sub(r\" N.J. \", \" new jersey \", text)\n",
    "    text = re.sub(r\" N.K. \", \" north korea \", text)\n",
    "    text = re.sub(r\" N.S.A. \", \" National Security Agency \", text)\n",
    "    text = re.sub(r\" N.Y. \", \" new york \", text)\n",
    "    text = re.sub(r\" P.E.I. \", \" Prince Edward Island \", text)\n",
    "    text = re.sub(r\" P.M. \", \" prime minister \", text)\n",
    "    text = re.sub(r\" P.R.C \", \" china \", text)\n",
    "    text = re.sub(r\" S.A. \", \" south africa \", text)\n",
    "    text = re.sub(r\" R.I. \", \" Rhode Island \", text)\n",
    "    text = re.sub(r\" U.A.E. \", \" United Arab Emirates \", text)\n",
    "    text = re.sub(r\" U.K. \", \" england \", text)\n",
    "    text = re.sub(r\" U.N. \", \" new jersey \", text)\n",
    "    text = re.sub(r\" U.S. \", \" america \", text)\n",
    "    text = re.sub(r\" U.S.C. \", \" university of south california \", text)\n",
    "    text = re.sub(r\" W.H.O \", \" world health organization \", text)\n",
    "    text = re.sub(r\" a.m. \", \" morning \", text)\n",
    "    text = re.sub(r\" p.m. \", \" afternoon \", text)\n",
    "    text = re.sub(r\" Ph.D. \", \" doctor of philosophy \", text)\n",
    "    text = re.sub(r\" sq.m. \", \" square meter \", text)\n",
    "    \n",
    "    # Tokenize the string into word tokens\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # further clean the tokens: split toekns like \"b'Russia\" which still have punctuations in the token\n",
    "    ls = []\n",
    "    for word in tokens:\n",
    "        if \"'\" in word:\n",
    "            ls = ls + word.split(\"'\")\n",
    "    tokens = tokens + ls\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if lemma_words:\n",
    "        tokens = [WordNetLemmatizer().lemmatize(word) for word in tokens]\n",
    "    \n",
    "    #Remove one letter tokens & non-alphabetic tokens, such as punctuation, then lower the tokens\n",
    "    tokens = [word.lower() for word in tokens if (word.isalpha() and len(word)>1)]\n",
    "\n",
    "    # remove stop words  \n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in final_stop]\n",
    "               \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each document to list of words\n",
    "df.news = df.news.apply(lambda x: text_to_wordlist(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['georgia',\n",
       " 'two',\n",
       " 'russian',\n",
       " 'warplane',\n",
       " 'country',\n",
       " 'move',\n",
       " 'brink',\n",
       " 'war',\n",
       " 'musharraf',\n",
       " 'impeached',\n",
       " 'columns',\n",
       " 'troop',\n",
       " 'roll',\n",
       " 'south',\n",
       " 'ossetia',\n",
       " 'footage',\n",
       " 'fighting',\n",
       " 'youtube',\n",
       " 'tank',\n",
       " 'moving',\n",
       " 'towards',\n",
       " 'capital',\n",
       " 'south',\n",
       " 'ossetia',\n",
       " 'reportedly',\n",
       " 'completely',\n",
       " 'destroyed',\n",
       " 'georgian',\n",
       " 'artillery',\n",
       " 'fire',\n",
       " 'afghan',\n",
       " 'child',\n",
       " 'raped',\n",
       " 'new',\n",
       " 'jersey',\n",
       " 'official',\n",
       " 'sick',\n",
       " 'three',\n",
       " 'year',\n",
       " 'old',\n",
       " 'wa',\n",
       " 'raped',\n",
       " 'nothing',\n",
       " 'russian',\n",
       " 'tank',\n",
       " 'entered',\n",
       " 'south',\n",
       " 'ossetia',\n",
       " 'georgia',\n",
       " 'shoot',\n",
       " 'two',\n",
       " 'russian',\n",
       " 'jet',\n",
       " 'georgia',\n",
       " 'invades',\n",
       " 'south',\n",
       " 'ossetia',\n",
       " 'russia',\n",
       " 'warned',\n",
       " 'would',\n",
       " 'intervene',\n",
       " 'side',\n",
       " 'combatent',\n",
       " 'trial',\n",
       " 'nothing',\n",
       " 'sham',\n",
       " 'salim',\n",
       " 'haman',\n",
       " 'sentenced',\n",
       " 'year',\n",
       " 'kept',\n",
       " 'longer',\n",
       " 'anyway',\n",
       " 'feel',\n",
       " 'troop',\n",
       " 'retreat',\n",
       " 'osettain',\n",
       " 'capital',\n",
       " 'presumably',\n",
       " 'leaving',\n",
       " 'several',\n",
       " 'hundred',\n",
       " 'people',\n",
       " 'killed',\n",
       " 'video',\n",
       " 'america',\n",
       " 'prep',\n",
       " 'georgia',\n",
       " 'war',\n",
       " 'russia',\n",
       " 'gives',\n",
       " 'green',\n",
       " 'light',\n",
       " 'israel',\n",
       " 'attack',\n",
       " 'iran',\n",
       " 'america',\n",
       " 'veto',\n",
       " 'israeli',\n",
       " 'military',\n",
       " 'ops',\n",
       " 'class',\n",
       " 'action',\n",
       " 'lawsuit',\n",
       " 'behalf',\n",
       " 'american',\n",
       " 'public',\n",
       " 'fbi',\n",
       " 'georgia',\n",
       " 'war',\n",
       " 'nyt',\n",
       " 'top',\n",
       " 'story',\n",
       " 'opening',\n",
       " 'ceremony',\n",
       " 'olympics',\n",
       " 'fucking',\n",
       " 'disgrace',\n",
       " 'yet',\n",
       " 'proof',\n",
       " 'decline',\n",
       " 'journalism',\n",
       " 'china',\n",
       " 'tell',\n",
       " 'bush',\n",
       " 'stay',\n",
       " 'country',\n",
       " 'affair',\n",
       " 'world',\n",
       " 'war',\n",
       " 'start',\n",
       " 'invades',\n",
       " 'south',\n",
       " 'ossetia',\n",
       " 'russia',\n",
       " 'get',\n",
       " 'involved',\n",
       " 'nato',\n",
       " 'absorb',\n",
       " 'georgia',\n",
       " 'unleash',\n",
       " 'full',\n",
       " 'scale',\n",
       " 'war',\n",
       " 'faces',\n",
       " 'islamist',\n",
       " 'backlash',\n",
       " 'rice',\n",
       " 'us',\n",
       " 'would',\n",
       " 'act',\n",
       " 'prevent',\n",
       " 'israeli',\n",
       " 'strike',\n",
       " 'iran',\n",
       " 'israeli',\n",
       " 'defense',\n",
       " 'minister',\n",
       " 'ehud',\n",
       " 'barak',\n",
       " 'israel',\n",
       " 'prepared',\n",
       " 'uncompromising',\n",
       " 'victory',\n",
       " 'case',\n",
       " 'military',\n",
       " 'hostility',\n",
       " 'busy',\n",
       " 'day',\n",
       " 'european',\n",
       " 'union',\n",
       " 'approved',\n",
       " 'new',\n",
       " 'sanction',\n",
       " 'iran',\n",
       " 'protest',\n",
       " 'nuclear',\n",
       " 'programme',\n",
       " 'georgia',\n",
       " 'withdraw',\n",
       " 'soldier',\n",
       " 'iraq',\n",
       " 'help',\n",
       " 'fight',\n",
       " 'russian',\n",
       " 'force',\n",
       " 'georgia',\n",
       " 'breakaway',\n",
       " 'region',\n",
       " 'south',\n",
       " 'ossetia',\n",
       " 'pentagon',\n",
       " 'thinks',\n",
       " 'attacking',\n",
       " 'iran',\n",
       " 'bad',\n",
       " 'idea',\n",
       " 'us',\n",
       " 'amp',\n",
       " 'world',\n",
       " 'report',\n",
       " 'crisis',\n",
       " 'georgia',\n",
       " 'invades',\n",
       " 'south',\n",
       " 'ossetia',\n",
       " 'shoe',\n",
       " 'manufactory',\n",
       " 'series',\n",
       " 'work',\n",
       " 'suffering',\n",
       " 'mental',\n",
       " 'illnesses',\n",
       " 'banned',\n",
       " 'olympics',\n",
       " 'help',\n",
       " 'mexico',\n",
       " 'kidnapping',\n",
       " 'surge',\n",
       " 'russia',\n",
       " 'russian',\n",
       " 'impunity',\n",
       " 'enemy',\n",
       " 'georgian',\n",
       " 'rice',\n",
       " 'announcing',\n",
       " 'georgia',\n",
       " 'condoleezza',\n",
       " 'caucasus',\n",
       " 'indian',\n",
       " 'visitors']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news_wordlists.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec --- Doc2vec  (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec model (trained on an enormous Google corpus)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Users/peiguo/Downloads/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02478027, -0.10986328,  0.06591797, -0.09130859,  0.17578125,\n",
       "        0.08007812, -0.18261719, -0.34765625, -0.16113281,  0.30859375,\n",
       "        0.13769531,  0.11181641,  0.12207031,  0.07128906,  0.00436401,\n",
       "       -0.20898438, -0.18945312,  0.08056641,  0.03393555, -0.07910156],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economy_vec = model['south']\n",
    "economy_vec[:20] # First 20 components of 300 total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(model, wordlist):\n",
    "    '''\n",
    "    Use a word2vec embedding model to get the vecter of each word of the wordlist.\n",
    "    Now we have a list of vecters, len(list)= number of words in the doc, len(vector)= the model type, e.g.300\n",
    "    Convert each doc into a vector by np.mean. len(doc vec) = 300\n",
    "    '''\n",
    "    # Filter the list of vectors to include only those that Word2Vec has a vector for\n",
    "    vector_list = [model[word] for word in wordlist if word in model.vocab]\n",
    "    doc_vector = np.mean(vector_list, axis=0)\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each document (list of words) to a document vecter, then save into a list of doc_vec\n",
    "x_doc = [doc2vec(model, doc) for doc in df.news]  \n",
    "X_doc= pd.Series(x_doc, name = 'doc_vec') # list to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00466015,  0.04605767,  0.03547058,  0.10155483, -0.03422928,\n",
       "       -0.01389613,  0.0094356 , -0.14502455,  0.03542512,  0.0929451 ,\n",
       "       -0.02405647, -0.13372633, -0.0746136 ,  0.03855896, -0.08115924,\n",
       "        0.10458709, -0.0641892 ,  0.0719087 ,  0.0019091 , -0.12026239],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 numbers in the first document vector\n",
    "X_doc[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1989,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>news</th>\n",
       "      <th>doc_vec</th>\n",
       "      <th>news_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[georgia, two, russian, warplane, country, mov...</td>\n",
       "      <td>[-0.0046601472, 0.046057668, 0.035470575, 0.10...</td>\n",
       "      <td>georgia two russian warplane country move brin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[wont, america, nato, help, wont, help, help, ...</td>\n",
       "      <td>[-0.01796527, 0.026893076, 0.05216946, 0.11043...</td>\n",
       "      <td>wont america nato help wont help help iraq put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[adorable, sang, opening, ceremony, wa, fake, ...</td>\n",
       "      <td>[0.020226372, 0.05665661, 0.038335405, 0.09110...</td>\n",
       "      <td>adorable sang opening ceremony wa fake russia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[america, refuse, israel, weapon, attack, iran...</td>\n",
       "      <td>[0.009319111, 0.04263116, 0.062353328, 0.08478...</td>\n",
       "      <td>america refuse israel weapon attack iran repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[expert, admit, legalise, drug, south, osetia,...</td>\n",
       "      <td>[0.01713654, 0.04969087, 0.062367942, 0.105228...</td>\n",
       "      <td>expert admit legalise drug south osetia pictur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                               news  \\\n",
       "0      0  [georgia, two, russian, warplane, country, mov...   \n",
       "1      1  [wont, america, nato, help, wont, help, help, ...   \n",
       "2      0  [adorable, sang, opening, ceremony, wa, fake, ...   \n",
       "3      0  [america, refuse, israel, weapon, attack, iran...   \n",
       "4      1  [expert, admit, legalise, drug, south, osetia,...   \n",
       "\n",
       "                                             doc_vec  \\\n",
       "0  [-0.0046601472, 0.046057668, 0.035470575, 0.10...   \n",
       "1  [-0.01796527, 0.026893076, 0.05216946, 0.11043...   \n",
       "2  [0.020226372, 0.05665661, 0.038335405, 0.09110...   \n",
       "3  [0.009319111, 0.04263116, 0.062353328, 0.08478...   \n",
       "4  [0.01713654, 0.04969087, 0.062367942, 0.105228...   \n",
       "\n",
       "                                            news_str  \n",
       "0  georgia two russian warplane country move brin...  \n",
       "1  wont america nato help wont help help iraq put...  \n",
       "2  adorable sang opening ceremony wa fake russia ...  \n",
       "3  america refuse israel weapon attack iran repor...  \n",
       "4  expert admit legalise drug south osetia pictur...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a new dataframe containing only label, news, doc_vec\n",
    "newdf = pd.concat([df.Label,df.news,X_doc], axis = 1)\n",
    "\n",
    "# convert each row in the news column from a list of tokens to a string\n",
    "tokenstrlist = []\n",
    "for tokenlist in  df.news:\n",
    "    tokenstr = ' '.join(tokenlist)\n",
    "    tokenstrlist.append(tokenstr)\n",
    "\n",
    "# add the string format new as clolumn 'news_str' to the data frame\n",
    "newdf['news_str'] = pd.Series(tokenstrlist)\n",
    "\n",
    "# the final data frame is ready for modeling\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_news_docvec_newsstr.pkl', 'wb') as f:\n",
    "    pickle.dump(newdf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
