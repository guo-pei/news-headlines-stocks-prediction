{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 6000\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>news</th>\n",
       "      <th>doc_vec</th>\n",
       "      <th>news_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[georgia, two, russian, warplane, country, mov...</td>\n",
       "      <td>[-0.0046601472, 0.046057668, 0.035470575, 0.10...</td>\n",
       "      <td>georgia two russian warplane country move brin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[wont, america, nato, help, wont, help, help, ...</td>\n",
       "      <td>[-0.01796527, 0.026893076, 0.05216946, 0.11043...</td>\n",
       "      <td>wont america nato help wont help help iraq put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[adorable, sang, opening, ceremony, wa, fake, ...</td>\n",
       "      <td>[0.020226372, 0.05665661, 0.038335405, 0.09110...</td>\n",
       "      <td>adorable sang opening ceremony wa fake russia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[america, refuse, israel, weapon, attack, iran...</td>\n",
       "      <td>[0.009319111, 0.04263116, 0.062353328, 0.08478...</td>\n",
       "      <td>america refuse israel weapon attack iran repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[expert, admit, legalise, drug, south, osetia,...</td>\n",
       "      <td>[0.01713654, 0.04969087, 0.062367942, 0.105228...</td>\n",
       "      <td>expert admit legalise drug south osetia pictur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                               news  \\\n",
       "0      0  [georgia, two, russian, warplane, country, mov...   \n",
       "1      1  [wont, america, nato, help, wont, help, help, ...   \n",
       "2      0  [adorable, sang, opening, ceremony, wa, fake, ...   \n",
       "3      0  [america, refuse, israel, weapon, attack, iran...   \n",
       "4      1  [expert, admit, legalise, drug, south, osetia,...   \n",
       "\n",
       "                                             doc_vec  \\\n",
       "0  [-0.0046601472, 0.046057668, 0.035470575, 0.10...   \n",
       "1  [-0.01796527, 0.026893076, 0.05216946, 0.11043...   \n",
       "2  [0.020226372, 0.05665661, 0.038335405, 0.09110...   \n",
       "3  [0.009319111, 0.04263116, 0.062353328, 0.08478...   \n",
       "4  [0.01713654, 0.04969087, 0.062367942, 0.105228...   \n",
       "\n",
       "                                            news_str  \n",
       "0  georgia two russian warplane country move brin...  \n",
       "1  wont america nato help wont help help iraq put...  \n",
       "2  adorable sang opening ceremony wa fake russia ...  \n",
       "3  america refuse israel weapon attack iran repor...  \n",
       "4  expert admit legalise drug south osetia pictur...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('label_news_docvec_newsstr.pkl', 'rb') as r:\n",
    "    df = pickle.load(r)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00466015,  0.04605767,  0.03547058,  0.10155483, -0.03422928,\n",
       "       -0.01389613,  0.0094356 , -0.14502455,  0.03542512,  0.0929451 ,\n",
       "       -0.02405647, -0.13372633, -0.0746136 ,  0.03855896, -0.08115924,\n",
       "        0.10458709, -0.0641892 ,  0.0719087 ,  0.0019091 , -0.12026239],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,2][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'georgia two russian warplane country move brink war musharraf impeached columns troop roll south ossetia footage fighting youtube tank moving towards capital south ossetia reportedly completely destroyed georgian artillery fire afghan child raped new jersey official sick three year old wa raped nothing russian tank entered south ossetia georgia shoot two russian jet georgia invades south ossetia russia warned would intervene side combatent trial nothing sham salim haman sentenced year kept longer anyway feel troop retreat osettain capital presumably leaving several hundred people killed video america prep georgia war russia gives green light israel attack iran america veto israeli military ops class action lawsuit behalf american public fbi georgia war nyt top story opening ceremony olympics fucking disgrace yet proof decline journalism china tell bush stay country affair world war start invades south ossetia russia get involved nato absorb georgia unleash full scale war faces islamist backlash rice us would act prevent israeli strike iran israeli defense minister ehud barak israel prepared uncompromising victory case military hostility busy day european union approved new sanction iran protest nuclear programme georgia withdraw soldier iraq help fight russian force georgia breakaway region south ossetia pentagon thinks attacking iran bad idea us amp world report crisis georgia invades south ossetia shoe manufactory series work suffering mental illnesses banned olympics help mexico kidnapping surge russia russian impunity enemy georgian rice announcing georgia condoleezza caucasus indian visitors'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:1688,:] # 85% for training and validation, 15% for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  svm, naive_bayes, neighbors, ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "nb_model = naive_bayes.GaussianNB()\n",
    "knn_model = neighbors.KNeighborsClassifier()\n",
    "svc_model = svm.SVC(probability=True, gamma=\"scale\")\n",
    "rf_model = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "et_model = ensemble.ExtraTreesClassifier(n_estimators=100)\n",
    "ada_model = ensemble.AdaBoostClassifier()\n",
    "xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, \n",
    "                              reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8)\n",
    "\n",
    "models = [\"lr_model\", \"nb_model\", \"knn_model\", \"svc_model\", \"rf_model\", \"et_model\", \"ada_model\", \"xgb_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model_filter(modellist, X, y):\n",
    "    ''' 1. split the train data further into train and validation (17%). \n",
    "        2. fit the train data into each model of the model list\n",
    "        3. get the classification report based on the model performance on validation data\n",
    "    '''\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size = 0.17, random_state = 100)\n",
    "    for model_name in modellist:\n",
    "        curr_model = eval(model_name)\n",
    "        curr_model.fit(X_train, y_train) \n",
    "        print(f'{model_name} \\n report:{classification_report(y_valid, curr_model.predict(X_valid))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try using different word embedding techniques to filter the baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-Of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word')\n",
    "X = count_vect.fit_transform(df_train.news_str).toarray()\n",
    "y = df_train.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.42      0.44       122\n",
      "           1       0.60      0.64      0.62       165\n",
      "\n",
      "    accuracy                           0.54       287\n",
      "   macro avg       0.53      0.53      0.53       287\n",
      "weighted avg       0.54      0.54      0.54       287\n",
      "\n",
      "nb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.39      0.39       122\n",
      "           1       0.55      0.55      0.55       165\n",
      "\n",
      "    accuracy                           0.48       287\n",
      "   macro avg       0.47      0.47      0.47       287\n",
      "weighted avg       0.48      0.48      0.48       287\n",
      "\n",
      "knn_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43       122\n",
      "           1       0.58      0.58      0.58       165\n",
      "\n",
      "    accuracy                           0.51       287\n",
      "   macro avg       0.50      0.50      0.50       287\n",
      "weighted avg       0.51      0.51      0.51       287\n",
      "\n",
      "svc_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.14      0.21       122\n",
      "           1       0.57      0.84      0.68       165\n",
      "\n",
      "    accuracy                           0.54       287\n",
      "   macro avg       0.48      0.49      0.44       287\n",
      "weighted avg       0.50      0.54      0.48       287\n",
      "\n",
      "rf_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.25      0.32       122\n",
      "           1       0.58      0.77      0.66       165\n",
      "\n",
      "    accuracy                           0.55       287\n",
      "   macro avg       0.51      0.51      0.49       287\n",
      "weighted avg       0.52      0.55      0.51       287\n",
      "\n",
      "et_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.37      0.41       122\n",
      "           1       0.59      0.68      0.63       165\n",
      "\n",
      "    accuracy                           0.55       287\n",
      "   macro avg       0.53      0.52      0.52       287\n",
      "weighted avg       0.54      0.55      0.54       287\n",
      "\n",
      "ada_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.41      0.43       122\n",
      "           1       0.59      0.64      0.61       165\n",
      "\n",
      "    accuracy                           0.54       287\n",
      "   macro avg       0.52      0.52      0.52       287\n",
      "weighted avg       0.53      0.54      0.54       287\n",
      "\n",
      "xgb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.32      0.35       122\n",
      "           1       0.55      0.61      0.57       165\n",
      "\n",
      "    accuracy                           0.48       287\n",
      "   macro avg       0.46      0.46      0.46       287\n",
      "weighted avg       0.47      0.48      0.48       287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_model_filter(models, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word')\n",
    "X = tfidf_vect.fit_transform(df_train.news_str).toarray()\n",
    "y = df_train.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.20      0.28       122\n",
      "           1       0.58      0.81      0.68       165\n",
      "\n",
      "    accuracy                           0.55       287\n",
      "   macro avg       0.51      0.51      0.48       287\n",
      "weighted avg       0.52      0.55      0.51       287\n",
      "\n",
      "nb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.37      0.38       122\n",
      "           1       0.56      0.59      0.57       165\n",
      "\n",
      "    accuracy                           0.49       287\n",
      "   macro avg       0.48      0.48      0.48       287\n",
      "weighted avg       0.49      0.49      0.49       287\n",
      "\n",
      "knn_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.47      0.45       122\n",
      "           1       0.58      0.55      0.57       165\n",
      "\n",
      "    accuracy                           0.52       287\n",
      "   macro avg       0.51      0.51      0.51       287\n",
      "weighted avg       0.52      0.52      0.52       287\n",
      "\n",
      "svc_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.02      0.03       122\n",
      "           1       0.57      0.98      0.72       165\n",
      "\n",
      "    accuracy                           0.57       287\n",
      "   macro avg       0.45      0.50      0.38       287\n",
      "weighted avg       0.47      0.57      0.43       287\n",
      "\n",
      "rf_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.27      0.32       122\n",
      "           1       0.56      0.70      0.62       165\n",
      "\n",
      "    accuracy                           0.52       287\n",
      "   macro avg       0.48      0.48      0.47       287\n",
      "weighted avg       0.49      0.52      0.50       287\n",
      "\n",
      "et_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.36      0.40       122\n",
      "           1       0.59      0.68      0.63       165\n",
      "\n",
      "    accuracy                           0.54       287\n",
      "   macro avg       0.52      0.52      0.52       287\n",
      "weighted avg       0.53      0.54      0.53       287\n",
      "\n",
      "ada_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43       122\n",
      "           1       0.56      0.50      0.53       165\n",
      "\n",
      "    accuracy                           0.48       287\n",
      "   macro avg       0.48      0.48      0.48       287\n",
      "weighted avg       0.49      0.48      0.49       287\n",
      "\n",
      "xgb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.39      0.40       122\n",
      "           1       0.57      0.59      0.58       165\n",
      "\n",
      "    accuracy                           0.51       287\n",
      "   macro avg       0.49      0.49      0.49       287\n",
      "weighted avg       0.50      0.51      0.50       287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_model_filter(models, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       122\n",
      "           1       0.57      1.00      0.73       165\n",
      "\n",
      "    accuracy                           0.57       287\n",
      "   macro avg       0.29      0.50      0.37       287\n",
      "weighted avg       0.33      0.57      0.42       287\n",
      "\n",
      "nb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.35      0.41       122\n",
      "           1       0.61      0.74      0.67       165\n",
      "\n",
      "    accuracy                           0.57       287\n",
      "   macro avg       0.55      0.55      0.54       287\n",
      "weighted avg       0.56      0.57      0.56       287\n",
      "\n",
      "knn_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.49      0.48       122\n",
      "           1       0.61      0.60      0.61       165\n",
      "\n",
      "    accuracy                           0.55       287\n",
      "   macro avg       0.55      0.55      0.55       287\n",
      "weighted avg       0.56      0.55      0.55       287\n",
      "\n",
      "svc_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       122\n",
      "           1       0.57      1.00      0.73       165\n",
      "\n",
      "    accuracy                           0.57       287\n",
      "   macro avg       0.29      0.50      0.37       287\n",
      "weighted avg       0.33      0.57      0.42       287\n",
      "\n",
      "rf_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.39      0.41       122\n",
      "           1       0.58      0.63      0.60       165\n",
      "\n",
      "    accuracy                           0.53       287\n",
      "   macro avg       0.51      0.51      0.51       287\n",
      "weighted avg       0.52      0.53      0.52       287\n",
      "\n",
      "et_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.31      0.34       122\n",
      "           1       0.55      0.63      0.59       165\n",
      "\n",
      "    accuracy                           0.49       287\n",
      "   macro avg       0.47      0.47      0.47       287\n",
      "weighted avg       0.48      0.49      0.48       287\n",
      "\n",
      "ada_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40       122\n",
      "           1       0.56      0.56      0.56       165\n",
      "\n",
      "    accuracy                           0.49       287\n",
      "   macro avg       0.48      0.48      0.48       287\n",
      "weighted avg       0.49      0.49      0.49       287\n",
      "\n",
      "xgb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.39      0.42       122\n",
      "           1       0.59      0.66      0.62       165\n",
      "\n",
      "    accuracy                           0.54       287\n",
      "   macro avg       0.52      0.52      0.52       287\n",
      "weighted avg       0.53      0.54      0.54       287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_chars_vect = TfidfVectorizer(analyzer='char')\n",
    "\n",
    "X = tfidf_chars_vect.fit_transform(df_train.news_str).toarray()\n",
    "y = df_train.Label\n",
    "\n",
    "baseline_model_filter(models, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.02      0.05       122\n",
      "           1       0.57      0.97      0.72       165\n",
      "\n",
      "    accuracy                           0.57       287\n",
      "   macro avg       0.47      0.50      0.38       287\n",
      "weighted avg       0.49      0.57      0.43       287\n",
      "\n",
      "nb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44       122\n",
      "           1       0.59      0.58      0.58       165\n",
      "\n",
      "    accuracy                           0.52       287\n",
      "   macro avg       0.51      0.51      0.51       287\n",
      "weighted avg       0.52      0.52      0.52       287\n",
      "\n",
      "knn_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.34      0.37       122\n",
      "           1       0.56      0.62      0.59       165\n",
      "\n",
      "    accuracy                           0.50       287\n",
      "   macro avg       0.48      0.48      0.48       287\n",
      "weighted avg       0.49      0.50      0.50       287\n",
      "\n",
      "svc_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       122\n",
      "           1       0.57      0.99      0.73       165\n",
      "\n",
      "    accuracy                           0.57       287\n",
      "   macro avg       0.29      0.50      0.36       287\n",
      "weighted avg       0.33      0.57      0.42       287\n",
      "\n",
      "rf_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.38       122\n",
      "           1       0.57      0.65      0.61       165\n",
      "\n",
      "    accuracy                           0.52       287\n",
      "   macro avg       0.50      0.50      0.50       287\n",
      "weighted avg       0.51      0.52      0.51       287\n",
      "\n",
      "et_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.30      0.36       122\n",
      "           1       0.59      0.75      0.66       165\n",
      "\n",
      "    accuracy                           0.56       287\n",
      "   macro avg       0.53      0.52      0.51       287\n",
      "weighted avg       0.54      0.56      0.53       287\n",
      "\n",
      "ada_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.44      0.44       122\n",
      "           1       0.58      0.56      0.57       165\n",
      "\n",
      "    accuracy                           0.51       287\n",
      "   macro avg       0.50      0.50      0.50       287\n",
      "weighted avg       0.51      0.51      0.51       287\n",
      "\n",
      "xgb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.38      0.40       122\n",
      "           1       0.57      0.62      0.59       165\n",
      "\n",
      "    accuracy                           0.52       287\n",
      "   macro avg       0.50      0.50      0.50       287\n",
      "weighted avg       0.51      0.52      0.51       287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array(list(df_train.doc_vec))\n",
    "y = np.array(list(df.Label[:1688]))\n",
    "baseline_model_filter(models, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best baseline model\n",
    "\n",
    "__Naive Bayes model with character based TF-IDF embedding__\n",
    "\n",
    "nb_model <br>\n",
    " report:              precision    recall  f1-score   support <br>\n",
    "\n",
    "           0       0.50      0.35      0.41       122\n",
    "           1       0.61      0.74      0.67       165\n",
    "\n",
    "    accuracy                           0.57       287\n",
    "   macro avg       0.55      0.55      0.54       287 <br>\n",
    "weighted avg       0.56      0.57      0.56       287 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## see performance on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[1688:,:]\n",
    "y_test = df_test.Label\n",
    "X_test = df_test.news_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09) \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.21      0.30       147\n",
      "           1       0.51      0.81      0.63       151\n",
      "\n",
      "    accuracy                           0.52       298\n",
      "   macro avg       0.52      0.51      0.47       298\n",
      "weighted avg       0.52      0.52      0.47       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_chars_vect = TfidfVectorizer(analyzer='char')\n",
    "train_news = tfidf_chars_vect.fit(df_train.news_str)\n",
    "X_train_trans = train_news.transform(df_train.news_str).toarray()\n",
    "X_test_trans = train_news.transform(X_test).toarray()\n",
    "\n",
    "y_train = df_train.Label\n",
    "\n",
    "nb_model.fit(X_train_trans, y_train) \n",
    "\n",
    "\n",
    "print(f'{nb_model} \\n report:{classification_report(y_test, nb_model.predict(X_test_trans))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
